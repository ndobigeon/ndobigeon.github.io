<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="description" content="Nicolas Dobigeon's professional web page" />
    <meta name="keywords" content="Nicolas Dobigeon, signal processing, bayesian inference, MCMC methods, monte carlo, markov chain" />
    <meta name="author" content="Nicolas Dobigeon" />
    <link rel="shortcut icon" href="../img/favicon_IRIT.ico" />
    <link rel="stylesheet" type="text/css" href="style_app.css" media="screen,projection" title="style_sc"/>
    <title>Nicolas Dobigeon @ University of Toulouse</title>
</head>

<body>

<div id="wrap">
    <div id="contentwide">

        <a href="../index.html">Home</a> / <a href="../research.html">Research</a> /
        <br/>
        <h1>Bayesian anti-sparse coding</h1>
        <p>
        Sparse representations have proven their efficiency in solving a wide class of inverse problems encountered in signal and image processing. Conversely, enforcing the information to be spread uniformly over representation coefficients exhibits relevant properties in various applications such as digital communications. Anti-sparse regularization can be naturally expressed through an l_\inf-norm penalty. This work derives a probabilistic formulation of such representations. A new probability distribution, referred to as the democratic prior, is first introduced. Its main properties as well as three random variate generators for this distribution are derived. Then this probability distribution is used as a prior to promote anti-sparsity in a Gaussian linear inverse problem, yielding a fully Bayesian formulation of anti-sparse coding. Two Markov chain Monte Carlo (MCMC) algorithms are proposed to generate samples according to the posterior distribution. The first one is a standard Gibbs sampler. The second one uses Metropolis-Hastings moves that exploit the proximity mapping of the log-posterior distribution. These samples are used to approximate maximum a posteriori and minimum mean square error estimators of both parameters and hyperparameters. Simulations on synthetic data illustrate the performances of the two proposed samplers, for both complete and over-complete dictionaries. All results are compared to the recent deterministic variational FITRA algorithm.
        <br/>
        <img alt="The democratic pdf" src="../demos/fig_anti_sparse_pdf.png" class="img_app"/><br/>
        Fig. 1. The democratic pdf.<br/>
        </p>

        <p>
            The democratic distribution and the Bayesian anti-sparse coding algorithm are detailed in the paper published in IEEE Trans. Signal Processing:
        </p>
        <ul>
        <li><a href="../papers/Elvira_IEEE_Trans_SP_2017.pdf">article <img src="../img/arxiv_icon.png" alt="Download the document" class="icon" /></a>.
        </li>
        </ul>
        <p>
            Complementary results are available in the following technical report.
        </p>
        <ul>
        <li><a href="../papers/Elvira_TechReport_2017.pdf">report <img src="../img/pdf_icon.png" alt="Download the document" class="icon" /></a>.
        </li>
        </ul>
        <p>
            The corresponding Matlab codes are available on Cl&eacute;ment Elvira's GitHub.
        </p>
        <ul>
        <li>matlab codes <a href="https://github.com/c-elvira/bayesian_antisparse_algorithm"><img src="../img/github_icon.png" alt="Download the software" class="icon" /></a>.
        </li>
        </ul>

    </div>
    <img class="hide" src="http://s20.sitemeter.com/meter.asp?site=s20dobigeon" alt="sitemeter stats"/><a class="hide" href="https://clustrmaps.com/site/19myh" title="Visit tracker"><img src="http://www.clustrmaps.com/map_v2.png?d=2eSX2TNFigOKEPj6Hx2qnt-gHV_ag30YNJldkXzQFlM&cl=ffffff"></a>
</div>
</body>
</html>
